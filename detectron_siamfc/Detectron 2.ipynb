{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, torchvision\n",
    "import glob\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "from IPython.display import display\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE = 'cpu'\n",
    "# print(cfg)\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "# outputs = predictor(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class_to_name = {\n",
    " 0: u'__background__',\n",
    " 1: u'person',\n",
    " 2: u'bicycle',\n",
    " 3: u'car',\n",
    " 4: u'motorcycle',\n",
    " 5: u'airplane',\n",
    " 6: u'bus',\n",
    " 7: u'train',\n",
    " 8: u'truck',\n",
    " 9: u'boat',\n",
    " 10: u'traffic light',\n",
    " 11: u'fire hydrant',\n",
    " 12: u'stop sign',\n",
    " 13: u'parking meter',\n",
    " 14: u'bench',\n",
    " 15: u'bird',\n",
    " 16: u'cat',\n",
    " 17: u'dog',\n",
    " 18: u'horse',\n",
    " 19: u'sheep',\n",
    " 20: u'cow',\n",
    " 21: u'elephant',\n",
    " 22: u'bear',\n",
    " 23: u'zebra',\n",
    " 24: u'giraffe',\n",
    " 25: u'backpack',\n",
    " 26: u'umbrella',\n",
    " 27: u'handbag',\n",
    " 28: u'tie',\n",
    " 29: u'suitcase',\n",
    " 30: u'frisbee',\n",
    " 31: u'skis',\n",
    " 32: u'snowboard',\n",
    " 33: u'sports ball',\n",
    " 34: u'kite',\n",
    " 35: u'baseball bat',\n",
    " 36: u'baseball glove',\n",
    " 37: u'skateboard',\n",
    " 38: u'surfboard',\n",
    " 39: u'tennis racket',\n",
    " 40: u'bottle',\n",
    " 41: u'wine glass',\n",
    " 42: u'cup',\n",
    " 43: u'fork',\n",
    " 44: u'knife',\n",
    " 45: u'spoon',\n",
    " 46: u'bowl',\n",
    " 47: u'banana',\n",
    " 48: u'apple',\n",
    " 49: u'sandwich',\n",
    " 50: u'orange',\n",
    " 51: u'broccoli',\n",
    " 52: u'carrot',\n",
    " 53: u'hot dog',\n",
    " 54: u'pizza',\n",
    " 55: u'donut',\n",
    " 56: u'cake',\n",
    " 57: u'chair',\n",
    " 58: u'couch',\n",
    " 59: u'potted plant',\n",
    " 60: u'bed',\n",
    " 61: u'dining table',\n",
    " 62: u'toilet',\n",
    " 63: u'tv',\n",
    " 64: u'laptop',\n",
    " 65: u'mouse',\n",
    " 66: u'remote',\n",
    " 67: u'keyboard',\n",
    " 68: u'cell phone',\n",
    " 69: u'microwave',\n",
    " 70: u'oven',\n",
    " 71: u'toaster',\n",
    " 72: u'sink',\n",
    " 73: u'refrigerator',\n",
    " 74: u'book',\n",
    " 75: u'clock',\n",
    " 76: u'vase',\n",
    " 77: u'scissors',\n",
    " 78: u'teddy bear',\n",
    " 79: u'hair drier',\n",
    " 80: u'toothbrush'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: video_dir/Woman/159.jpg \r\n",
      "\n",
      "number of instances: 3\r\n",
      "\n",
      "scores: [0.9950755  0.9912326  0.97894245] \r\n",
      "\n",
      "boxes: [[  0.      144.08621 143.3418  265.20654]\n",
      " [223.10535 117.14489 263.53635 187.36656]\n",
      " [200.02107 174.90598 350.6258  277.12656]]\r\n",
      "\n",
      "classes: [2 0 2]\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fullName = \"video_dir/Woman/159.jpg\"\n",
    "\n",
    "fileName = fullName.split('/')[-1]\n",
    "img = cv2.imread(fullName)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "#     display(Image.fromarray(img))\n",
    "outputs = predictor(img)\n",
    "\n",
    "\n",
    "v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "img = out.get_image()[:, :, ::-1]\n",
    "\n",
    "\n",
    "#     print(outputs[\"instances\"].get_fields()['pred_boxes'].tensor.numpy().reshape(1, -1))\n",
    "#     print(outputs[\"instances\"].get_fields()['pred_classes'].numpy())\n",
    "\n",
    "number_of_instances = len(outputs[\"instances\"])\n",
    "scores = outputs[\"instances\"].get_fields()['scores'].numpy()\n",
    "boxes = outputs[\"instances\"].get_fields()['pred_boxes'].tensor.numpy()\n",
    "classes = outputs[\"instances\"].get_fields()['pred_classes'].numpy()\n",
    "\n",
    "print(f\"file name: {fullName} \\r\\n\")\n",
    "print(f\"number of instances: {number_of_instances}\\r\\n\")\n",
    "print(f\"scores: {scores} \\r\\n\")\n",
    "print(f\"boxes: {boxes}\\r\\n\")\n",
    "print(f\"classes: {classes}\\r\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.0, 144.0, 143.0, 121.0), 'car')\n",
      "((223.0, 117.0, 40.0, 70.0), 'person')\n",
      "((200.0, 174.0, 150.0, 102.0), 'car')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(f\"classes: {classes}\\r\\n\")\n",
    "# print([ class_to_name[n+1] for n in classes ])\n",
    "\n",
    "# print(boxes[0])\n",
    "\n",
    "currBoxes = boxes.copy()\n",
    "\n",
    "for i in range(len(currBoxes)):\n",
    "    currBoxes[i] = [ int( currBoxes[i][0] ), \n",
    "                     int( currBoxes[i][1] ), \n",
    "                     int( currBoxes[i][2] - currBoxes[i][0] ), \n",
    "                     int( currBoxes[i][3] - currBoxes[i][1] ) ]\n",
    "    \n",
    "    print( tuple( [ tuple(currBoxes[i]), class_to_name[classes[i]+1] ] ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
